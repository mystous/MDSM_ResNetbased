{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.1+cu116)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchvision) (2.22.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: pandas in /usr/local/lib/python3.8/dist-packages (1.5.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.20.3; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: torchsummary in /usr/local/lib/python3.8/dist-packages (1.5.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "!pip install --upgrade pandas\n",
    "!pip install --upgrade torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from ResNet import Bottleneck, ResNet, ResNet50\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import models\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, out_planes, i_downsample=None, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        # stride를 통해 너비와 높이 조정\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        \n",
    "        # stride = 1, padding = 1이므로, 너비와 높이는 항시 유지됨\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        \n",
    "        # x를 그대로 더해주기 위함\n",
    "        self.shortcut = nn.Sequential()\n",
    "        self.i_downsample = i_downsample\n",
    "        \n",
    "        \n",
    "        # 만약 size가 안맞아 합연산이 불가하다면, 연산 가능하도록 모양을 맞춰줌\n",
    "        if stride != 1: # x와 \n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_planes)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(x) # 필요에 따라 layer를 Skip\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "def ResNet18(num_classes, channels=3):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes, channels)\n",
    "\n",
    "def ResNet34(num_classes, channels=3):\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_random(col, row, mdsm_body):\n",
    "    size_suffle = random.randint(0,10)\n",
    "    switchsource = torch.randint(0, row - 1, (size_suffle,))\n",
    "    temp = np.zeros((1, col), np.float32)\n",
    "    \n",
    "    for i in range(0, int(size_suffle)):\n",
    "        if i == switchsource[i]:\n",
    "            continue\n",
    "        temp = mdsm_body[i, :].copy()\n",
    "        mdsm_body[i, :] = mdsm_body[switchsource[i], :].copy()\n",
    "        mdsm_body[switchsource[i], :] = temp.copy()\n",
    "    return torch.tensor(mdsm_body)\n",
    "\n",
    "def flip_random(col, row, mdsm_body):\n",
    "    size_suffle = random.randint(0,10)\n",
    "    if size_suffle % 2 == 0:\n",
    "        return torch.tensor(mdsm_body)\n",
    "    \n",
    "    int_row = int(row)\n",
    "    for i in range(0, int(int_row / 2)):\n",
    "        temp = mdsm_body[i, :].copy()\n",
    "        mdsm_body[i, :] = mdsm_body[int_row - i - 1, :].copy()\n",
    "        mdsm_body[int_row - i - 1, :] = temp.copy()\n",
    "    return torch.tensor(mdsm_body)\n",
    "    \n",
    "class MDSMDataset(Dataset):\n",
    "    def __init__(self, mdsmdata_file):\n",
    "        self.df = pd.read_csv(mdsmdata_file)\n",
    "        rating = self.df[['ReviewID', 'reviewStar']]\n",
    "        self.rating = rating.drop_duplicates('ReviewID')\n",
    "        self.height = self.df['ReviewID'].value_counts().max()\n",
    "\n",
    "        mdsm_body = self.df.drop(['reviewNo', 'reviewStar'], axis=1)\n",
    "        mdsm_body['imageCnt'] = (mdsm_body['imageCnt'] - mdsm_body['imageCnt'].min())/ (mdsm_body['imageCnt'].max() - mdsm_body['imageCnt'].min())\n",
    "        mdsm_body['helpfulCnt'] = (mdsm_body['helpfulCnt'] - mdsm_body['helpfulCnt'].mean())/ mdsm_body['helpfulCnt'].std()\n",
    "        body_height, body_width = mdsm_body.shape;\n",
    "        self.width = body_width - 1\n",
    "\n",
    "        dummy_mdsd = np.zeros((body_height, self.height, self.width), np.float32)\n",
    "        mdsm_index = np.zeros(self.rating['ReviewID'].max()+1, int)\n",
    "        mdsm_count = np.zeros(self.rating['ReviewID'].max()+1, int)\n",
    "        mdsm_index.fill(-1)\n",
    "\n",
    "        max_index = int(0)\n",
    "        for index, body in mdsm_body.iterrows():\n",
    "            dummy_index = max_index\n",
    "            if mdsm_index[int(body['ReviewID'])] != -1:\n",
    "                dummy_index = mdsm_index[int(body['ReviewID'])]\n",
    "            else:\n",
    "                mdsm_index[int(body['ReviewID'])] = dummy_index\n",
    "                max_index = max_index + 1\n",
    "\n",
    "            dummy_mdsd[dummy_index, mdsm_count[dummy_index]] = body.drop('ReviewID')\n",
    "            mdsm_count[dummy_index] = mdsm_count[dummy_index] + 1\n",
    "\n",
    "        self.mdsm_body = dummy_mdsd\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.rating.shape[0]\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if trans_stat == True:\n",
    "            _tensor = flip_random(self.width, self.height, self.mdsm_body[idx])\n",
    "        else:\n",
    "            _tensor = torch.tensor(self.mdsm_body[idx])\n",
    "        rtn_tensor = _tensor.unsqueeze(0)\n",
    "        return rtn_tensor, self.rating.iloc[idx, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Loading dataset--\n",
      "-- Building train and test dataset / dataloader--\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 54, 6]           3,136\n",
      "       BatchNorm2d-2            [-1, 64, 54, 6]             128\n",
      "              ReLU-3            [-1, 64, 54, 6]               0\n",
      "         MaxPool2d-4            [-1, 64, 27, 3]               0\n",
      "            Conv2d-5            [-1, 64, 27, 3]          36,864\n",
      "       BatchNorm2d-6            [-1, 64, 27, 3]             128\n",
      "            Conv2d-7            [-1, 64, 27, 3]          36,864\n",
      "       BatchNorm2d-8            [-1, 64, 27, 3]             128\n",
      "        BasicBlock-9            [-1, 64, 27, 3]               0\n",
      "           Conv2d-10            [-1, 64, 27, 3]          36,864\n",
      "      BatchNorm2d-11            [-1, 64, 27, 3]             128\n",
      "           Conv2d-12            [-1, 64, 27, 3]          36,864\n",
      "      BatchNorm2d-13            [-1, 64, 27, 3]             128\n",
      "       BasicBlock-14            [-1, 64, 27, 3]               0\n",
      "           Conv2d-15           [-1, 128, 14, 2]          73,728\n",
      "      BatchNorm2d-16           [-1, 128, 14, 2]             256\n",
      "           Conv2d-17           [-1, 128, 14, 2]         147,456\n",
      "      BatchNorm2d-18           [-1, 128, 14, 2]             256\n",
      "           Conv2d-19           [-1, 128, 14, 2]           8,192\n",
      "      BatchNorm2d-20           [-1, 128, 14, 2]             256\n",
      "       BasicBlock-21           [-1, 128, 14, 2]               0\n",
      "           Conv2d-22           [-1, 128, 14, 2]         147,456\n",
      "      BatchNorm2d-23           [-1, 128, 14, 2]             256\n",
      "           Conv2d-24           [-1, 128, 14, 2]         147,456\n",
      "      BatchNorm2d-25           [-1, 128, 14, 2]             256\n",
      "       BasicBlock-26           [-1, 128, 14, 2]               0\n",
      "           Conv2d-27            [-1, 256, 7, 1]         294,912\n",
      "      BatchNorm2d-28            [-1, 256, 7, 1]             512\n",
      "           Conv2d-29            [-1, 256, 7, 1]         589,824\n",
      "      BatchNorm2d-30            [-1, 256, 7, 1]             512\n",
      "           Conv2d-31            [-1, 256, 7, 1]          32,768\n",
      "      BatchNorm2d-32            [-1, 256, 7, 1]             512\n",
      "       BasicBlock-33            [-1, 256, 7, 1]               0\n",
      "           Conv2d-34            [-1, 256, 7, 1]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 7, 1]             512\n",
      "           Conv2d-36            [-1, 256, 7, 1]         589,824\n",
      "      BatchNorm2d-37            [-1, 256, 7, 1]             512\n",
      "       BasicBlock-38            [-1, 256, 7, 1]               0\n",
      "           Conv2d-39            [-1, 512, 4, 1]       1,179,648\n",
      "      BatchNorm2d-40            [-1, 512, 4, 1]           1,024\n",
      "           Conv2d-41            [-1, 512, 4, 1]       2,359,296\n",
      "      BatchNorm2d-42            [-1, 512, 4, 1]           1,024\n",
      "           Conv2d-43            [-1, 512, 4, 1]         131,072\n",
      "      BatchNorm2d-44            [-1, 512, 4, 1]           1,024\n",
      "       BasicBlock-45            [-1, 512, 4, 1]               0\n",
      "           Conv2d-46            [-1, 512, 4, 1]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 4, 1]           1,024\n",
      "           Conv2d-48            [-1, 512, 4, 1]       2,359,296\n",
      "      BatchNorm2d-49            [-1, 512, 4, 1]           1,024\n",
      "       BasicBlock-50            [-1, 512, 4, 1]               0\n",
      "AdaptiveAvgPool2d-51            [-1, 512, 1, 1]               0\n",
      "           Linear-52                    [-1, 6]           3,078\n",
      "================================================================\n",
      "Total params: 11,173,318\n",
      "Trainable params: 11,173,318\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.59\n",
      "Params size (MB): 42.62\n",
      "Estimated Total Size (MB): 44.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-- Loading dataset--')\n",
    "\n",
    "#dataset = MDSMDataset('amazon_hmdvr_df_tokenized_sentiment_score_extended.csv')\n",
    "dataset = MDSMDataset('amazon_hmdvr_df_tokenized_sentiment_score_extended_normalized.csv')\n",
    "train_size = len(dataset) * 0.8\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "print('-- Building train and test dataset / dataloader--')\n",
    "train_dataset, test_dataset = random_split(dataset, [int(train_size),int(test_size)])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size = 512, shuffle=True, num_workers=0)\n",
    "#trainloader = torch.utils.data.DataLoader(dataset, batch_size = 256, shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size = 512, shuffle=True, num_workers=0)\n",
    "\n",
    "classes = ['0', '1', '2', '3', '4', '5']\n",
    "\n",
    "#classes = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "#net = ResNet50(6, 1).to('cuda')\n",
    "#net = ResNet18(6, 1).to('cuda')\n",
    "net = ResNet34(6, 1).to('cuda')\n",
    "\n",
    "summary(net, (1, 108, 12))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Start training :  50 epochs\n",
      "Train Epoch: 0 Average loss: 0.0031 Accuracy : 54.0567%)\n",
      "Train Epoch: 1 Average loss: 0.0025 Accuracy : 58.5532%)\n",
      "Train Epoch: 2 Average loss: 0.0023 Accuracy : 61.1692%)\n",
      "Train Epoch: 3 Average loss: 0.0022 Accuracy : 62.6024%)\n",
      "Train Epoch: 4 Average loss: 0.0022 Accuracy : 62.9512%)\n",
      "Train Epoch: 5 Average loss: 0.0021 Accuracy : 63.3985%)\n",
      "Train Epoch: 6 Average loss: 0.0021 Accuracy : 63.2014%)\n",
      "Train Epoch: 7 Average loss: 0.0021 Accuracy : 62.8374%)\n",
      "Train Epoch: 8 Average loss: 0.0021 Accuracy : 63.4440%)\n",
      "Train Epoch: 9 Average loss: 0.0021 Accuracy : 63.5350%)\n",
      "Train Epoch: 10 Average loss: 0.0021 Accuracy : 63.7019%)\n",
      "Train Epoch: 11 Average loss: 0.0020 Accuracy : 63.8004%)\n",
      "Train Epoch: 12 Average loss: 0.0020 Accuracy : 63.5578%)\n",
      "Train Epoch: 13 Average loss: 0.0020 Accuracy : 63.8232%)\n",
      "Train Epoch: 14 Average loss: 0.0020 Accuracy : 63.7853%)\n",
      "Train Epoch: 15 Average loss: 0.0020 Accuracy : 63.8838%)\n",
      "Train Epoch: 16 Average loss: 0.0020 Accuracy : 64.0127%)\n",
      "Train Epoch: 17 Average loss: 0.0020 Accuracy : 64.2781%)\n",
      "Train Epoch: 18 Average loss: 0.0020 Accuracy : 63.9445%)\n",
      "Train Epoch: 19 Average loss: 0.0020 Accuracy : 64.3464%)\n",
      "Train Epoch: 20 Average loss: 0.0020 Accuracy : 64.3843%)\n",
      "Train Epoch: 21 Average loss: 0.0020 Accuracy : 64.2023%)\n",
      "Train Epoch: 22 Average loss: 0.0020 Accuracy : 64.2857%)\n",
      "Train Epoch: 23 Average loss: 0.0020 Accuracy : 64.3767%)\n",
      "Train Epoch: 24 Average loss: 0.0020 Accuracy : 64.4449%)\n",
      "Train Epoch: 25 Average loss: 0.0020 Accuracy : 64.4829%)\n",
      "Train Epoch: 26 Average loss: 0.0020 Accuracy : 64.5056%)\n",
      "Train Epoch: 27 Average loss: 0.0020 Accuracy : 64.4449%)\n",
      "Train Epoch: 28 Average loss: 0.0020 Accuracy : 65.0743%)\n",
      "Train Epoch: 29 Average loss: 0.0020 Accuracy : 64.6648%)\n",
      "Train Epoch: 30 Average loss: 0.0020 Accuracy : 64.6497%)\n",
      "Train Epoch: 31 Average loss: 0.0020 Accuracy : 65.0212%)\n",
      "Train Epoch: 32 Average loss: 0.0020 Accuracy : 65.1426%)\n",
      "Train Epoch: 33 Average loss: 0.0020 Accuracy : 64.9075%)\n",
      "Train Epoch: 34 Average loss: 0.0019 Accuracy : 65.1122%)\n",
      "Train Epoch: 35 Average loss: 0.0019 Accuracy : 64.9833%)\n",
      "Train Epoch: 36 Average loss: 0.0019 Accuracy : 64.9530%)\n",
      "Train Epoch: 37 Average loss: 0.0019 Accuracy : 65.3549%)\n",
      "Train Epoch: 38 Average loss: 0.0019 Accuracy : 65.5596%)\n",
      "Train Epoch: 39 Average loss: 0.0019 Accuracy : 65.4004%)\n",
      "Train Epoch: 40 Average loss: 0.0019 Accuracy : 65.4459%)\n",
      "Train Epoch: 41 Average loss: 0.0019 Accuracy : 65.6809%)\n",
      "Train Epoch: 42 Average loss: 0.0019 Accuracy : 65.6506%)\n",
      "Train Epoch: 43 Average loss: 0.0019 Accuracy : 66.0373%)\n",
      "Train Epoch: 44 Average loss: 0.0019 Accuracy : 66.0525%)\n",
      "Train Epoch: 45 Average loss: 0.0019 Accuracy : 66.1662%)\n",
      "Train Epoch: 46 Average loss: 0.0019 Accuracy : 65.9766%)\n",
      "Train Epoch: 47 Average loss: 0.0019 Accuracy : 66.3103%)\n",
      "Train Epoch: 48 Average loss: 0.0019 Accuracy : 66.6363%)\n",
      "Train Epoch: 49 Average loss: 0.0019 Accuracy : 66.3482%)\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "EPOCHS = 50\n",
    "trans_stat = True\n",
    "print('-- Start training : ', EPOCHS, 'epochs')\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []\n",
    "    running_loss = 0\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for i, inp in enumerate(trainloader):\n",
    "        inputs, labels = inp\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        pred = outputs.data.max(1, keepdim=True)[1]\n",
    "        train_acc += pred.eq(labels.data.view_as(pred)).sum()\n",
    "\n",
    "        if i%100 == 0 and i > 0:\n",
    "            print(f'Loss [{epoch+1}/{EPOCHS}, {i}](epoch, minibatch): ', f'{running_loss / 100:.5f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    train_loss /= len(trainloader.dataset)\n",
    "    print('Train Epoch: {} Average loss: {:.4f} Accuracy : {:.4f}%)'.format(epoch, train_loss, 100. * train_acc / len(trainloader.dataset)))\n",
    "\n",
    "print('Training Done')\n",
    "trans_stat = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 10,000 test images:  61.632 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy on 10,000 test images: ', f'{100*(correct/total):.3f}', '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(outputs.data)\n",
    "        print(predicted)\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
