{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.1+cu116)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchvision) (2.22.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: pandas in /usr/local/lib/python3.8/dist-packages (1.5.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.20.3; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "!pip install --upgrade pandas\n",
    "!pip install --upgrade torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ResNet import Bottleneck, ResNet, ResNet50\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import models\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDSMDataset(Dataset):\n",
    "    def __init__(self, mdsmdata_file):\n",
    "        self.df = pd.read_csv(mdsmdata_file)\n",
    "        rating = self.df[['ReviewID', 'reviewStar']]\n",
    "        self.rating = rating.drop_duplicates('ReviewID')\n",
    "        self.height = self.df['ReviewID'].value_counts().max()\n",
    "\n",
    "        mdsm_body = self.df.drop(['reviewNo', 'reviewStar'], axis=1)\n",
    "        mdsm_body['imageCnt'] = (mdsm_body['imageCnt'] - mdsm_body['imageCnt'].min())/ (mdsm_body['imageCnt'].max() - mdsm_body['imageCnt'].min())\n",
    "        mdsm_body['helpfulCnt'] = (mdsm_body['helpfulCnt'] - mdsm_body['helpfulCnt'].mean())/ mdsm_body['helpfulCnt'].std()\n",
    "        body_height, body_width = mdsm_body.shape;\n",
    "        self.width = body_width - 1\n",
    "\n",
    "        dummy_mdsd = np.zeros((body_height, self.height, self.width), np.float32)\n",
    "        mdsm_index = np.zeros(self.rating['ReviewID'].max()+1, int)\n",
    "        mdsm_count = np.zeros(self.rating['ReviewID'].max()+1, int)\n",
    "        mdsm_index.fill(-1)\n",
    "\n",
    "        max_index = int(0)\n",
    "        for index, body in mdsm_body.iterrows():\n",
    "            dummy_index = max_index\n",
    "            if mdsm_index[int(body['ReviewID'])] != -1:\n",
    "                dummy_index = mdsm_index[int(body['ReviewID'])]\n",
    "            else:\n",
    "                mdsm_index[int(body['ReviewID'])] = dummy_index\n",
    "                max_index = max_index + 1\n",
    "\n",
    "            dummy_mdsd[dummy_index, mdsm_count[dummy_index]] = body.drop('ReviewID')\n",
    "            mdsm_count[dummy_index] = mdsm_count[dummy_index] + 1\n",
    "\n",
    "        self.mdsm_body = dummy_mdsd\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.rating.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _tensor = torch.tensor(self.mdsm_body[idx])\n",
    "        rtn_tensor = _tensor.unsqueeze(0)\n",
    "        return rtn_tensor, self.rating.iloc[idx, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Loading dataset--\n",
      "-- Building train and test dataset / dataloader--\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 54, 6]           3,136\n",
      "       BatchNorm2d-2            [-1, 64, 54, 6]             128\n",
      "              ReLU-3            [-1, 64, 54, 6]               0\n",
      "         MaxPool2d-4            [-1, 64, 27, 3]               0\n",
      "            Conv2d-5            [-1, 64, 27, 3]           4,160\n",
      "       BatchNorm2d-6            [-1, 64, 27, 3]             128\n",
      "              ReLU-7            [-1, 64, 27, 3]               0\n",
      "            Conv2d-8            [-1, 64, 27, 3]          36,928\n",
      "       BatchNorm2d-9            [-1, 64, 27, 3]             128\n",
      "             ReLU-10            [-1, 64, 27, 3]               0\n",
      "           Conv2d-11           [-1, 256, 27, 3]          16,640\n",
      "      BatchNorm2d-12           [-1, 256, 27, 3]             512\n",
      "           Conv2d-13           [-1, 256, 27, 3]          16,640\n",
      "      BatchNorm2d-14           [-1, 256, 27, 3]             512\n",
      "             ReLU-15           [-1, 256, 27, 3]               0\n",
      "       Bottleneck-16           [-1, 256, 27, 3]               0\n",
      "           Conv2d-17            [-1, 64, 27, 3]          16,448\n",
      "      BatchNorm2d-18            [-1, 64, 27, 3]             128\n",
      "             ReLU-19            [-1, 64, 27, 3]               0\n",
      "           Conv2d-20            [-1, 64, 27, 3]          36,928\n",
      "      BatchNorm2d-21            [-1, 64, 27, 3]             128\n",
      "             ReLU-22            [-1, 64, 27, 3]               0\n",
      "           Conv2d-23           [-1, 256, 27, 3]          16,640\n",
      "      BatchNorm2d-24           [-1, 256, 27, 3]             512\n",
      "             ReLU-25           [-1, 256, 27, 3]               0\n",
      "       Bottleneck-26           [-1, 256, 27, 3]               0\n",
      "           Conv2d-27            [-1, 64, 27, 3]          16,448\n",
      "      BatchNorm2d-28            [-1, 64, 27, 3]             128\n",
      "             ReLU-29            [-1, 64, 27, 3]               0\n",
      "           Conv2d-30            [-1, 64, 27, 3]          36,928\n",
      "      BatchNorm2d-31            [-1, 64, 27, 3]             128\n",
      "             ReLU-32            [-1, 64, 27, 3]               0\n",
      "           Conv2d-33           [-1, 256, 27, 3]          16,640\n",
      "      BatchNorm2d-34           [-1, 256, 27, 3]             512\n",
      "             ReLU-35           [-1, 256, 27, 3]               0\n",
      "       Bottleneck-36           [-1, 256, 27, 3]               0\n",
      "           Conv2d-37           [-1, 128, 27, 3]          32,896\n",
      "      BatchNorm2d-38           [-1, 128, 27, 3]             256\n",
      "             ReLU-39           [-1, 128, 27, 3]               0\n",
      "           Conv2d-40           [-1, 128, 14, 2]         147,584\n",
      "      BatchNorm2d-41           [-1, 128, 14, 2]             256\n",
      "             ReLU-42           [-1, 128, 14, 2]               0\n",
      "           Conv2d-43           [-1, 512, 14, 2]          66,048\n",
      "      BatchNorm2d-44           [-1, 512, 14, 2]           1,024\n",
      "           Conv2d-45           [-1, 512, 14, 2]         131,584\n",
      "      BatchNorm2d-46           [-1, 512, 14, 2]           1,024\n",
      "             ReLU-47           [-1, 512, 14, 2]               0\n",
      "       Bottleneck-48           [-1, 512, 14, 2]               0\n",
      "           Conv2d-49           [-1, 128, 14, 2]          65,664\n",
      "      BatchNorm2d-50           [-1, 128, 14, 2]             256\n",
      "             ReLU-51           [-1, 128, 14, 2]               0\n",
      "           Conv2d-52           [-1, 128, 14, 2]         147,584\n",
      "      BatchNorm2d-53           [-1, 128, 14, 2]             256\n",
      "             ReLU-54           [-1, 128, 14, 2]               0\n",
      "           Conv2d-55           [-1, 512, 14, 2]          66,048\n",
      "      BatchNorm2d-56           [-1, 512, 14, 2]           1,024\n",
      "             ReLU-57           [-1, 512, 14, 2]               0\n",
      "       Bottleneck-58           [-1, 512, 14, 2]               0\n",
      "           Conv2d-59           [-1, 128, 14, 2]          65,664\n",
      "      BatchNorm2d-60           [-1, 128, 14, 2]             256\n",
      "             ReLU-61           [-1, 128, 14, 2]               0\n",
      "           Conv2d-62           [-1, 128, 14, 2]         147,584\n",
      "      BatchNorm2d-63           [-1, 128, 14, 2]             256\n",
      "             ReLU-64           [-1, 128, 14, 2]               0\n",
      "           Conv2d-65           [-1, 512, 14, 2]          66,048\n",
      "      BatchNorm2d-66           [-1, 512, 14, 2]           1,024\n",
      "             ReLU-67           [-1, 512, 14, 2]               0\n",
      "       Bottleneck-68           [-1, 512, 14, 2]               0\n",
      "           Conv2d-69           [-1, 128, 14, 2]          65,664\n",
      "      BatchNorm2d-70           [-1, 128, 14, 2]             256\n",
      "             ReLU-71           [-1, 128, 14, 2]               0\n",
      "           Conv2d-72           [-1, 128, 14, 2]         147,584\n",
      "      BatchNorm2d-73           [-1, 128, 14, 2]             256\n",
      "             ReLU-74           [-1, 128, 14, 2]               0\n",
      "           Conv2d-75           [-1, 512, 14, 2]          66,048\n",
      "      BatchNorm2d-76           [-1, 512, 14, 2]           1,024\n",
      "             ReLU-77           [-1, 512, 14, 2]               0\n",
      "       Bottleneck-78           [-1, 512, 14, 2]               0\n",
      "           Conv2d-79           [-1, 256, 14, 2]         131,328\n",
      "      BatchNorm2d-80           [-1, 256, 14, 2]             512\n",
      "             ReLU-81           [-1, 256, 14, 2]               0\n",
      "           Conv2d-82            [-1, 256, 7, 1]         590,080\n",
      "      BatchNorm2d-83            [-1, 256, 7, 1]             512\n",
      "             ReLU-84            [-1, 256, 7, 1]               0\n",
      "           Conv2d-85           [-1, 1024, 7, 1]         263,168\n",
      "      BatchNorm2d-86           [-1, 1024, 7, 1]           2,048\n",
      "           Conv2d-87           [-1, 1024, 7, 1]         525,312\n",
      "      BatchNorm2d-88           [-1, 1024, 7, 1]           2,048\n",
      "             ReLU-89           [-1, 1024, 7, 1]               0\n",
      "       Bottleneck-90           [-1, 1024, 7, 1]               0\n",
      "           Conv2d-91            [-1, 256, 7, 1]         262,400\n",
      "      BatchNorm2d-92            [-1, 256, 7, 1]             512\n",
      "             ReLU-93            [-1, 256, 7, 1]               0\n",
      "           Conv2d-94            [-1, 256, 7, 1]         590,080\n",
      "      BatchNorm2d-95            [-1, 256, 7, 1]             512\n",
      "             ReLU-96            [-1, 256, 7, 1]               0\n",
      "           Conv2d-97           [-1, 1024, 7, 1]         263,168\n",
      "      BatchNorm2d-98           [-1, 1024, 7, 1]           2,048\n",
      "             ReLU-99           [-1, 1024, 7, 1]               0\n",
      "      Bottleneck-100           [-1, 1024, 7, 1]               0\n",
      "          Conv2d-101            [-1, 256, 7, 1]         262,400\n",
      "     BatchNorm2d-102            [-1, 256, 7, 1]             512\n",
      "            ReLU-103            [-1, 256, 7, 1]               0\n",
      "          Conv2d-104            [-1, 256, 7, 1]         590,080\n",
      "     BatchNorm2d-105            [-1, 256, 7, 1]             512\n",
      "            ReLU-106            [-1, 256, 7, 1]               0\n",
      "          Conv2d-107           [-1, 1024, 7, 1]         263,168\n",
      "     BatchNorm2d-108           [-1, 1024, 7, 1]           2,048\n",
      "            ReLU-109           [-1, 1024, 7, 1]               0\n",
      "      Bottleneck-110           [-1, 1024, 7, 1]               0\n",
      "          Conv2d-111            [-1, 256, 7, 1]         262,400\n",
      "     BatchNorm2d-112            [-1, 256, 7, 1]             512\n",
      "            ReLU-113            [-1, 256, 7, 1]               0\n",
      "          Conv2d-114            [-1, 256, 7, 1]         590,080\n",
      "     BatchNorm2d-115            [-1, 256, 7, 1]             512\n",
      "            ReLU-116            [-1, 256, 7, 1]               0\n",
      "          Conv2d-117           [-1, 1024, 7, 1]         263,168\n",
      "     BatchNorm2d-118           [-1, 1024, 7, 1]           2,048\n",
      "            ReLU-119           [-1, 1024, 7, 1]               0\n",
      "      Bottleneck-120           [-1, 1024, 7, 1]               0\n",
      "          Conv2d-121            [-1, 256, 7, 1]         262,400\n",
      "     BatchNorm2d-122            [-1, 256, 7, 1]             512\n",
      "            ReLU-123            [-1, 256, 7, 1]               0\n",
      "          Conv2d-124            [-1, 256, 7, 1]         590,080\n",
      "     BatchNorm2d-125            [-1, 256, 7, 1]             512\n",
      "            ReLU-126            [-1, 256, 7, 1]               0\n",
      "          Conv2d-127           [-1, 1024, 7, 1]         263,168\n",
      "     BatchNorm2d-128           [-1, 1024, 7, 1]           2,048\n",
      "            ReLU-129           [-1, 1024, 7, 1]               0\n",
      "      Bottleneck-130           [-1, 1024, 7, 1]               0\n",
      "          Conv2d-131            [-1, 256, 7, 1]         262,400\n",
      "     BatchNorm2d-132            [-1, 256, 7, 1]             512\n",
      "            ReLU-133            [-1, 256, 7, 1]               0\n",
      "          Conv2d-134            [-1, 256, 7, 1]         590,080\n",
      "     BatchNorm2d-135            [-1, 256, 7, 1]             512\n",
      "            ReLU-136            [-1, 256, 7, 1]               0\n",
      "          Conv2d-137           [-1, 1024, 7, 1]         263,168\n",
      "     BatchNorm2d-138           [-1, 1024, 7, 1]           2,048\n",
      "            ReLU-139           [-1, 1024, 7, 1]               0\n",
      "      Bottleneck-140           [-1, 1024, 7, 1]               0\n",
      "          Conv2d-141            [-1, 512, 7, 1]         524,800\n",
      "     BatchNorm2d-142            [-1, 512, 7, 1]           1,024\n",
      "            ReLU-143            [-1, 512, 7, 1]               0\n",
      "          Conv2d-144            [-1, 512, 4, 1]       2,359,808\n",
      "     BatchNorm2d-145            [-1, 512, 4, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 4, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 4, 1]       1,050,624\n",
      "     BatchNorm2d-148           [-1, 2048, 4, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 4, 1]       2,099,200\n",
      "     BatchNorm2d-150           [-1, 2048, 4, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 4, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 4, 1]               0\n",
      "          Conv2d-153            [-1, 512, 4, 1]       1,049,088\n",
      "     BatchNorm2d-154            [-1, 512, 4, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 4, 1]               0\n",
      "          Conv2d-156            [-1, 512, 4, 1]       2,359,808\n",
      "     BatchNorm2d-157            [-1, 512, 4, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 4, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 4, 1]       1,050,624\n",
      "     BatchNorm2d-160           [-1, 2048, 4, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 4, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 4, 1]               0\n",
      "          Conv2d-163            [-1, 512, 4, 1]       1,049,088\n",
      "     BatchNorm2d-164            [-1, 512, 4, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 4, 1]               0\n",
      "          Conv2d-166            [-1, 512, 4, 1]       2,359,808\n",
      "     BatchNorm2d-167            [-1, 512, 4, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 4, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 4, 1]       1,050,624\n",
      "     BatchNorm2d-170           [-1, 2048, 4, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 4, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 4, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                    [-1, 6]          12,294\n",
      "================================================================\n",
      "Total params: 23,540,550\n",
      "Trainable params: 23,540,550\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 9.47\n",
      "Params size (MB): 89.80\n",
      "Estimated Total Size (MB): 99.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-- Loading dataset--')\n",
    "dataset = MDSMDataset('amazon_hmdvr_df_tokenized_sentiment_score_extended.csv')\n",
    "\n",
    "train_size = len(dataset) * 0.8\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "print('-- Building train and test dataset / dataloader--')\n",
    "train_dataset, test_dataset = random_split(dataset, [int(train_size),int(test_size)])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size = 64, shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size = 64, shuffle=True, num_workers=0)\n",
    "\n",
    "classes = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "net = ResNet50(6, 1).to('cuda')\n",
    "\n",
    "summary(net, (1, 108, 12))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Start training :  10 epochs\n",
      "Loss [1/10, 100](epoch, minibatch):  1.18017\n",
      "Loss [1/10, 200](epoch, minibatch):  1.15644\n",
      "Train Epoch: 0 Average loss: 0.0182 Accuracy : 59.2963%)\n",
      "Loss [2/10, 100](epoch, minibatch):  1.15956\n",
      "Loss [2/10, 200](epoch, minibatch):  1.17990\n",
      "Train Epoch: 1 Average loss: 0.0183 Accuracy : 58.8338%)\n",
      "Loss [3/10, 100](epoch, minibatch):  1.17675\n",
      "Loss [3/10, 200](epoch, minibatch):  1.14503\n",
      "Train Epoch: 2 Average loss: 0.0181 Accuracy : 59.1826%)\n",
      "Loss [4/10, 100](epoch, minibatch):  1.16493\n",
      "Loss [4/10, 200](epoch, minibatch):  1.15032\n",
      "Train Epoch: 3 Average loss: 0.0180 Accuracy : 59.0764%)\n",
      "Loss [5/10, 100](epoch, minibatch):  1.17411\n",
      "Loss [5/10, 200](epoch, minibatch):  1.13587\n",
      "Train Epoch: 4 Average loss: 0.0180 Accuracy : 59.3873%)\n",
      "Loss [6/10, 100](epoch, minibatch):  1.14983\n",
      "Loss [6/10, 200](epoch, minibatch):  1.15605\n",
      "Train Epoch: 5 Average loss: 0.0180 Accuracy : 59.2812%)\n",
      "Loss [7/10, 100](epoch, minibatch):  1.15064\n",
      "Loss [7/10, 200](epoch, minibatch):  1.14748\n",
      "Train Epoch: 6 Average loss: 0.0179 Accuracy : 59.5086%)\n",
      "Loss [8/10, 100](epoch, minibatch):  1.15706\n",
      "Loss [8/10, 200](epoch, minibatch):  1.14292\n",
      "Train Epoch: 7 Average loss: 0.0180 Accuracy : 59.4631%)\n",
      "Loss [9/10, 100](epoch, minibatch):  1.15184\n",
      "Loss [9/10, 200](epoch, minibatch):  1.14236\n",
      "Train Epoch: 8 Average loss: 0.0179 Accuracy : 59.4783%)\n",
      "Loss [10/10, 100](epoch, minibatch):  1.13567\n",
      "Loss [10/10, 200](epoch, minibatch):  1.14649\n",
      "Train Epoch: 9 Average loss: 0.0179 Accuracy : 59.8423%)\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "EPOCHS = 10\n",
    "print('-- Start training : ', EPOCHS, 'epochs')\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []\n",
    "    running_loss = 0\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for i, inp in enumerate(trainloader):\n",
    "        inputs, labels = inp\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        pred = outputs.data.max(1, keepdim=True)[1]\n",
    "        train_acc += pred.eq(labels.data.view_as(pred)).sum()\n",
    "\n",
    "        if i%100 == 0 and i > 0:\n",
    "            print(f'Loss [{epoch+1}/{EPOCHS}, {i}](epoch, minibatch): ', f'{running_loss / 100:.5f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    train_loss /= len(trainloader.dataset)\n",
    "    print('Train Epoch: {} Average loss: {:.4f} Accuracy : {:.4f}%)'.format(epoch, train_loss, 100. * train_acc / len(trainloader.dataset)))\n",
    "\n",
    "print('Training Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 10,000 test images:  58.083 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy on 10,000 test images: ', f'{100*(correct/total):.3f}', '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
